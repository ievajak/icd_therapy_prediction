{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import glob\n",
    "from statistics import mean\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sktime.transformations.panel.tsfresh import TSFreshFeatureExtractor\n",
    "from sktime.datatypes import check_is_mtype, convert\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, recall_score, roc_curve, auc, make_scorer, confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold, mutual_info_classif, RFE\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold, train_test_split, cross_val_score\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "import shap\n",
    "\n",
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import tensorflow as tf\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Conv1D, Dropout, MaxPooling1D, Flatten, Dense, GlobalAveragePooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed value for the project.\n",
    "seed_value = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outcome variables - as decided with the host organisation.\n",
    "# These values correspond to a ventricular fibrillation.\n",
    "OUTCOMES = [\n",
    "'ATP in VT/VF delivered',\n",
    "'ATP One Shot delivered',\n",
    "'VT1 therapy episodes',\n",
    "'VF episodes',\n",
    "'ATP in VT zones started',\n",
    "'ATP One Shot started',\n",
    "'ATP in VT zones successful',\n",
    "'ATP One Shot successful',\n",
    "'Shocks started',\n",
    "'Shocks aborted',\n",
    "'Shocks successful']\n",
    "\n",
    "# Feature variables specific to patients with single chamber ICDs (ventricular).\n",
    "VENTR_FEATURES = ['RV pacing impedance [ohm]',\n",
    " 'RV sensing amplitude (daily mean) [mV]',\n",
    " 'RV sensing amplitude (daily min.) [mV]',\n",
    " 'Daily shock lead impedance [ohm]',\n",
    " 'Right ven. pacing (RVp) [%]',\n",
    " 'VT1 monitoring episodes',\n",
    " 'VT1 therapy episodes',\n",
    " 'VT2 episodes',\n",
    " 'VF episodes',\n",
    " 'Episodes during temporary program',\n",
    " 'ATP in VT zones started',\n",
    " 'ATP in VT zones successful',\n",
    " 'ATP One Shot started',\n",
    " 'ATP One Shot successful',\n",
    " 'Shocks started',\n",
    " 'Shocks aborted',\n",
    " 'Shocks successful',\n",
    " 'Ineffective ven. max. energy shocks',\n",
    " 'Mean ventricular heart rate [bpm]',\n",
    " 'Mean ventricular heart rate at rest [bpm]',\n",
    " 'Patient activity [% of day]',\n",
    " 'ATP in VT/VF delivered',\n",
    " 'ATP One Shot delivered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VENTR_FEATURES = [i for i in VENTR_FEATURES if i not in OUTCOMES+[ 'VT1 monitoring episodes', 'VT2 episodes', 'Episodes during temporary program', 'Ineffective ven. max. energy shocks']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RV pacing impedance [ohm]',\n",
       " 'RV sensing amplitude (daily mean) [mV]',\n",
       " 'RV sensing amplitude (daily min.) [mV]',\n",
       " 'Daily shock lead impedance [ohm]',\n",
       " 'Right ven. pacing (RVp) [%]',\n",
       " 'VT1 monitoring episodes',\n",
       " 'VT1 therapy episodes',\n",
       " 'VT2 episodes',\n",
       " 'VF episodes',\n",
       " 'Episodes during temporary program',\n",
       " 'ATP in VT zones started',\n",
       " 'ATP in VT zones successful',\n",
       " 'ATP One Shot started',\n",
       " 'ATP One Shot successful',\n",
       " 'Shocks started',\n",
       " 'Shocks aborted',\n",
       " 'Shocks successful',\n",
       " 'Ineffective ven. max. energy shocks',\n",
       " 'Mean ventricular heart rate [bpm]',\n",
       " 'Mean ventricular heart rate at rest [bpm]',\n",
       " 'Patient activity [% of day]',\n",
       " 'ATP in VT/VF delivered',\n",
       " 'ATP One Shot delivered']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VENTR_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generating cases and controls lists of patient IDs. \n",
    "# case_path = os.getcwd() + '/data/the_rest/the_full_data/Deidentified_data/Cases'\n",
    "# contr_path = os.getcwd() + '/data/the_rest/the_full_data/Deidentified_data/Controls'\n",
    "# case_files = glob.glob(os.path.join(case_path, \"*.csv\"))\n",
    "# contr_files = glob.glob(os.path.join(contr_path, \"*.csv\"))\n",
    "\n",
    "# cases = []\n",
    "# controls = []\n",
    "\n",
    "# # Creating a list of cases IDs.\n",
    "# for f in case_files:\n",
    "#     to_replace = case_path + '/'\n",
    "#     case_id = f.replace(to_replace, '')\n",
    "#     case_id = case_id.replace('.csv', '')\n",
    "#     cases.append(int(case_id))\n",
    "\n",
    "# # Creating a list of control IDs.\n",
    "# for f in contr_files:\n",
    "#     to_replace = contr_path + '/'\n",
    "#     contr_id = f.replace(to_replace, '')\n",
    "#     contr_id = contr_id.replace('.csv', '')\n",
    "#     controls.append(int(contr_id))\n",
    "\n",
    "# # Creating a list of all patient IDs.\n",
    "# all_patients = cases + controls\n",
    "\n",
    "# # Checking which patients were not included. \n",
    "# set(np.array(range(1,226))) - set(all_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcome_df = pd.read_csv(os.getcwd()+'/cleaned_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "splitting function  \n",
    "function to run the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaper 2 returns a 2D df with patient_id and index in columns. \n",
    "class DataReshaper4(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        Converts 3d np array into 2d np array.\n",
    "        '''\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        num_samples, num_time_steps, num_features = X.shape\n",
    "        reshaped = X.reshape(num_samples, num_time_steps * num_features)\n",
    "        return reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_xgb(df, window_size=30):\n",
    "    \"\"\"\n",
    "    Splits the input DataFrame based on specified conditions for generating\n",
    "    training data for the XGBoost model.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df - pd.DataFrame\n",
    "        The input DataFrame containing patient data.\n",
    "    window_size - int\n",
    "        The size of the window to extract data before the 'shock' event. \n",
    "        Default is 30.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    new_df - pd.DataFrame\n",
    "        A new DataFrame containing the extracted input data.\n",
    "    outcome - list\n",
    "        A list of outcome labels (1 for ICD therapy, 0 for non-cases).\n",
    "    \"\"\"\n",
    "    outcome = []\n",
    "    new_df = pd.DataFrame()\n",
    "    pt_id = df['patient_id'].unique()\n",
    "    \n",
    "    for n in pt_id:\n",
    "        pt_data = df[df['patient_id'] == n]\n",
    "        is_case = pt_data['case'].iloc[0] == 1\n",
    "\n",
    "        if is_case:\n",
    "            for i, row in pt_data.iterrows():\n",
    "                if row['shock'] > 0 and row['index'] > window_size:\n",
    "                    inp_df = df.loc[i - (window_size):i - 1].copy()\n",
    "                    new_df = pd.concat([new_df, inp_df])\n",
    "                    outcome.append(1)\n",
    "                    break\n",
    "        else:\n",
    "            mid_index = len(pt_data) // 2\n",
    "            inp_df = pt_data.iloc[mid_index - (window_size+1):mid_index - 1].copy()\n",
    "            outcome.append(0)\n",
    "            new_df = pd.concat([new_df, inp_df])\n",
    "\n",
    "\n",
    "    return new_df, outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_one_sample_model(X_all_extr, y_all_extr, classifier, n_splits=5): \n",
    "\n",
    "    # Initialize your model (e.g., RandomForestClassifier)\n",
    "    model = classifier\n",
    "\n",
    "    # Lists to store evaluation metrics\n",
    "    roc_auc_scores = []\n",
    "    accuracy_scores = []\n",
    "    predicted_proba = []\n",
    "    observed = []\n",
    "    sensitivity_scores = []\n",
    "    specificity_scores = []\n",
    "    \n",
    "    # Converting data into days x features columns. \n",
    "    resh4 = DataReshaper4()\n",
    "    xgb_2d = resh4.transform(X_all_extr)\n",
    "    \n",
    "    X = xgb_2d#xgb_dat.copy()\n",
    "    y = y_all_extr#np.array(outcome)\n",
    "\n",
    "    cross_validator = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    # Perform manual cross-validation\n",
    "    for i, (train_idx, val_idx) in enumerate(cross_validator.split(X, y)):\n",
    "        X_train, X_val = X[train_idx], X[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "\n",
    "\n",
    "        # Fitting the model to acquire roc_auc, accuracy, sensitiv./specific.\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred_proba = model.predict_proba(X_val)\n",
    "        y_pred_class = (y_pred_proba[:, 1] >= 0.5).astype(int)\n",
    "        \n",
    "        # Storing predicted probabilities and true values for this fold.\n",
    "        predicted_proba.append(y_pred_proba[:, 1])\n",
    "        observed.append(y_val)\n",
    "        \n",
    "        # Calculating accuracy and ROC-AUC for this fold, adding to lists.\n",
    "        roc_extr = roc_auc_score(y_val, y_pred_proba[:, 1])\n",
    "        accu_extr = accuracy_score(y_val, y_pred_class)\n",
    "        \n",
    "        # Storing ROC-AUC and accuracy for this fold\n",
    "        roc_auc_scores.append(roc_extr)\n",
    "        accuracy_scores.append(accu_extr)\n",
    "        \n",
    "        # Calculating the confusion matrix for this fold.\n",
    "        conf_matrix = confusion_matrix(y_val, y_pred_class)\n",
    "        \n",
    "        # Calculating sensitivity and specificity for this fold.\n",
    "        tn, fp, fn, tp = conf_matrix.ravel()\n",
    "        sensitivity = tp / (tp + fn)\n",
    "        specificity = tn / (tn + fp)\n",
    "        \n",
    "        # Storing sensitivity and specificity for this fold.\n",
    "        sensitivity_scores.append(sensitivity)\n",
    "        specificity_scores.append(specificity)\n",
    "\n",
    "    if n_splits == 10:\n",
    "        roc_low_conf = mean(roc_auc_scores) - 1.96*(np.std(roc_auc_scores))\n",
    "        roc_up_conf = mean(roc_auc_scores) + 1.96*(np.std(roc_auc_scores))\n",
    "        ac_low_conf = mean(accuracy_scores) - 1.96*(np.std(accuracy_scores))\n",
    "        ac_up_conf = mean(accuracy_scores) + 1.96*(np.std(accuracy_scores))\n",
    "\n",
    "        print(f\"ROC-AUC 95% CI: {roc_low_conf.round(3)} - {roc_up_conf.round(3)}\")\n",
    "        print(f\"Accuracy 95% CI: {ac_low_conf.round(3)} - {ac_up_conf.round(3)}\")\n",
    "\n",
    "    # Printing the metrics    \n",
    "    print(f\"Accuracy score: {np.mean(accuracy_scores).round(3)}\")\n",
    "    print(f\"ROC-AUC score: {np.mean(roc_auc_scores).round(3)}\")\n",
    "    print(f\"Sensitivity scores: {np.mean(sensitivity_scores).round(3)}\")\n",
    "    print(f\"Specificity scores: {np.mean(specificity).round(3)}\")\n",
    "\n",
    "    return (predicted_proba, observed, roc_auc_scores, accuracy_scores, sensitivity_scores,\n",
    "    specificity_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrangling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 4\n",
    "\n",
    "\n",
    "# Generating the input dataframe for XGBoost with pre-defined window size.\n",
    "split_df, outcome = split_xgb(outcome_df.drop('level_0', axis=1).reset_index(), WINDOW_SIZE)\n",
    "# Droping the outcome columns.\n",
    "split_df = split_df.drop('case', axis=1)\n",
    "split_df = split_df.drop('shock', axis=1)\n",
    "split_df = split_df.drop('level_0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FEAT = len(split_df.columns) - 2 # subtracting patient_id and index.\n",
    "N_PT = int(len(split_df)/WINDOW_SIZE)\n",
    "xgb_dat = np.empty((N_PT, N_FEAT, WINDOW_SIZE))\n",
    "pt_id = split_df['patient_id'].unique()\n",
    "pt_count = 0\n",
    "# Looping through patient IDs.\n",
    "for n in pt_id:\n",
    "    pt_count \n",
    "    pt_data = split_df[split_df['patient_id']==n].copy()\n",
    "\n",
    "    # Looping through days in the window.\n",
    "    for i in range(len(VENTR_FEATURES)):\n",
    "        xgb_dat[pt_count, i, :] = np.array(pt_data[VENTR_FEATURES].iloc[:, i])\n",
    "    pt_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC 95% CI: 0.455 - 0.918\n",
      "Accuracy 95% CI: 0.693 - 0.939\n",
      "Accuracy score: 0.816\n",
      "ROC-AUC score: 0.687\n",
      "Sensitivity scores: 0.225\n",
      "Specificity scores: 0.882\n"
     ]
    }
   ],
   "source": [
    "classifier = xgb.XGBClassifier()\n",
    "(pred_y, true_y, roc_auc_scores, accuracy_scores, sensitivity_scores,\n",
    "specificity_scores) = running_one_sample_model(xgb_dat, np.array(outcome),\n",
    "classifier, n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bootstrapping Test Predictions - CIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confidence interval for the score: [0.594 - 0.763]\n"
     ]
    }
   ],
   "source": [
    "n_bootstraps = 1000\n",
    "bootstrapped_scores = []\n",
    "pred_flat_y = np.concatenate(pred_y)\n",
    "true_flat_y = np.concatenate(true_y)\n",
    "\n",
    "rng = np.random.RandomState(seed_value)\n",
    "for i in range(n_bootstraps):\n",
    "    # bootstrap by sampling with replacement on the prediction indices\n",
    "    indices = rng.randint(0, len(pred_flat_y), len(pred_flat_y))\n",
    "    bootstrapped_true_y = true_flat_y[indices]  # Use indices for bootstrapped samples\n",
    "    \n",
    "    if len(np.unique(bootstrapped_true_y)) < 2:\n",
    "        continue\n",
    "        # We need at least one positive and one negative sample for ROC AUC\n",
    "        # to be defined: reject the sample\n",
    "\n",
    "    bootstrapped_pred_y = pred_flat_y[indices]  # Use indices for bootstrapped samples\n",
    "    score = roc_auc_score(bootstrapped_true_y, bootstrapped_pred_y)\n",
    "    bootstrapped_scores.append(score)\n",
    "\n",
    "\n",
    "sorted_scores = np.array(bootstrapped_scores)\n",
    "sorted_scores.sort()\n",
    "\n",
    "# Computing the lower and upper bound of the 90% confidence interval\n",
    "# You can change the bounds percentiles to 0.025 and 0.975 to get\n",
    "# a 95% confidence interval instead.\n",
    "confidence_lower = sorted_scores[int(0.05 * len(sorted_scores))]\n",
    "confidence_upper = sorted_scores[int(0.95 * len(sorted_scores))]\n",
    "print(\"Confidence interval for the score: [{:0.3f} - {:0.3}]\".format(\n",
    "    confidence_lower, confidence_upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting ROC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenate the observed and predicted_proba lists across all folds\n",
    "observed_all = np.concatenate(true_y)\n",
    "predicted_proba_all = np.concatenate(pred_y)\n",
    "\n",
    "# Compute ROC curve and AUC for the combined data\n",
    "fpr, tpr, _ = roc_curve(observed_all, predicted_proba_all)\n",
    "roc_auc_cnn = auc(fpr, tpr)\n",
    "\n",
    "# Calculate sensitivity and specificity from the ROC curve data\n",
    "sensitivity = tpr\n",
    "specificity = 1 - fpr\n",
    "\n",
    "# Plot sensitivity-specificity curve\n",
    "plt.figure()\n",
    "plt.plot(1 - specificity, sensitivity, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc_cnn)\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title('Sensitivity-Specificity Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating best concurrent specificity and sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity at 0.9% Specificity: 0.3902439024390244\n",
      "Best Threshold: 0.2100\n",
      "Best Sensitivity: 0.4878\n",
      "Best Specificity: 0.8757\n"
     ]
    }
   ],
   "source": [
    "# Calculate Youden's J statistic for each threshold\n",
    "youden_j_values = np.array(sensitivity) + np.array(specificity) - 1\n",
    "thresholds = np.arange(0.0, 1.01, 0.01)\n",
    "\n",
    "# Find the index of the threshold that maximizes Youden's J value\n",
    "best_threshold_index = np.argmax(youden_j_values)\n",
    "\n",
    "# Get the corresponding threshold and its sensitivity and specificity values\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "best_sensitivity = sensitivity[best_threshold_index]\n",
    "best_specificity = specificity[best_threshold_index]\n",
    "\n",
    "# Desired specificity level\n",
    "desired_specificity = 0.9\n",
    "\n",
    "# Find the index in the specificity array that is closest to the desired specificity\n",
    "closest_index = np.argmin(np.abs(specificity - desired_specificity))\n",
    "\n",
    "# Get the corresponding sensitivity value at the closest index\n",
    "sensitivity_at_desired_specificity = sensitivity[closest_index]\n",
    "\n",
    "print(f\"Sensitivity at {desired_specificity}% Specificity:\", sensitivity_at_desired_specificity)\n",
    "\n",
    "print(f\"Best Threshold: {best_threshold:.4f}\")\n",
    "print(f\"Best Sensitivity: {best_sensitivity:.4f}\")\n",
    "print(f\"Best Specificity: {best_specificity:.4f}\")\n",
    "\n",
    "# Best Threshold: 0.2800\n",
    "# Best Sensitivity: 0.7791\n",
    "# Best Specificity: 0.8333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "WINDOW_SIZE = 10\n",
    "N_FEAT = outcome_df.shape[1]-6\n",
    "n_splits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReshaper1(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    A custom data transformation class that reshapes 3D data into a tabular\n",
    "    format with both patient ID and time in the rows.\n",
    "\n",
    "    It can be used as part of a data preprocessing pipeline to reshape 3D data\n",
    "    into a tabular format.\n",
    "\n",
    "    Methods:\n",
    "    __init__(self): Constructor method, initializes the object.\n",
    "    fit(self, X, y=None): Fit method, returns the object itself.\n",
    "    transform(self, X): Transforms the input 3D data into a tabular DataFrame.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Transforms the input 3D data into a tabular DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        X np.matrix\n",
    "            The input 3D data with patient, day, and feature dimensions.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        df pd.DataFrame\n",
    "            The tabular DataFrame with reshaped data.\n",
    "        \"\"\"\n",
    "        # Calculate the number of features (columns) in the original DataFrame.\n",
    "        n_feat = X.shape[2]\n",
    "\n",
    "        # Create an empty list to store data rows.\n",
    "        rows = []\n",
    "\n",
    "        # Loop through each patient and each day in the window.\n",
    "        for pt_count in range(X.shape[0]):\n",
    "            for i in range(WINDOW_SIZE):\n",
    "                # Get the data for the current day and patient.\n",
    "                data_for_day = X[pt_count, i, :]\n",
    "                pt_id = pt_count + 1  # Assuming patient_id starts from 1.\n",
    "\n",
    "                # Create a dictionary to store the row data.\n",
    "                row_data = {'patient_id': pt_id, 'index': i + 1}\n",
    "\n",
    "                # Add the VENTR_FEATURES data to the dictionary.\n",
    "                for j, feature in enumerate(VENTR_FEATURES):\n",
    "                    row_data[feature] = data_for_day[j]\n",
    "\n",
    "                # Append the row data to the list of rows.\n",
    "                rows.append(row_data)\n",
    "\n",
    "            # Create a pandas DataFrame from the list of rows.\n",
    "            df = pd.DataFrame(rows)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilising the min max scaler class for data normalisation. \n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReshaper2(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        '''\n",
    "        A custom data transformation class that reshapes data to a 3D numpy\n",
    "        array for Convolutional Neural Networks (CNNs). \n",
    "\n",
    "        It can be used as part of a data preprocessing pipeline to reshape data\n",
    "        for CNNs.\n",
    "\n",
    "        Methods:\n",
    "        __init__(self): Constructor method, initializes the object.\n",
    "        fit(self, X, y=None): Fit method, returns the object itself.\n",
    "        transform(self, X): Transforms the input data into a 3D numpy array.\n",
    "        '''\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        '''\n",
    "        Transforms the input data into a format suitable for CNNs. \n",
    "        Utilises previous data labels to create a 3D numpy array after scaling\n",
    "        with MinMaxScaler().\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        X pd.DataFrame\n",
    "            The input data with scaled values.\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        cnn_dat np.ndarray\n",
    "            The transformed data in a format suitable for CNNs.'''\n",
    "\n",
    "        column_names = ['patient_id']+['index']+VENTR_FEATURES\n",
    "        scaled_df = pd.DataFrame(X, columns=column_names)\n",
    "\n",
    "        n_feat = len(scaled_df.columns) - 2 # subtracting patient_id and index.\n",
    "        n_pt = int(len(scaled_df)/WINDOW_SIZE)\n",
    "        cnn_dat = np.empty((n_pt, WINDOW_SIZE, n_feat))\n",
    "\n",
    "        pt_id = scaled_df['patient_id'].unique()\n",
    "        pt_count = 0\n",
    "        # Looping through patient IDs.\n",
    "        for n in pt_id:\n",
    "            pt_count \n",
    "            pt_data = scaled_df[scaled_df['patient_id']==n].copy()\n",
    "\n",
    "            # Looping through days in the window.\n",
    "            for i in range(WINDOW_SIZE):\n",
    "                cnn_dat[pt_count, i, :] = np.array(pt_data[VENTR_FEATURES].iloc[i])\n",
    "            pt_count += 1\n",
    "\n",
    "        return cnn_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_binary_classifier_model_1(learning_rate=0.001):\n",
    "    \"\"\"\n",
    "    Creates a binary classifier model using Convolutional Neural Networks (CNNs).\n",
    "\n",
    "    This function creates a binary classifier model using TensorFlow and Keras.\n",
    "    The model architecture consists of two Conv1D layers with ReLU activation,\n",
    "    followed by a Flatten layer, two Dense layers with ReLU activation, and an\n",
    "    output Dense layer with a sigmoid activation for binary classification.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    learning_rate float, optional\n",
    "        The learning rate for the Adam optimizer. Default is 0.001.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    model tf.keras.Model\n",
    "        The binary classifier model.\n",
    "    \"\"\"\n",
    "    model = Sequential([\n",
    "        Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(WINDOW_SIZE, N_FEAT)),\n",
    "        Conv1D(filters=64, kernel_size=2, activation='relu'),\n",
    "        Dropout(0,5),\n",
    "        Flatten(),\n",
    "        Dense(100, activation='relu'),\n",
    "        Dropout(0,5),\n",
    "        Dense(1, activation='sigmoid')  # Output layer with one neuron and sigmoid activation\n",
    "    ])\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)  # Specify the learning rate for Adam optimizer\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics='accuracy')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "pipeline_1 = Pipeline([\n",
    "    ('reshape1', DataReshaper1()),\n",
    "    ('scaler', MinMaxScaler()),\n",
    "    ('reshape2', DataReshaper2()),\n",
    "    ('cnn', KerasClassifier(model=create_binary_classifier_model_1, epochs=20, batch_size=32, validation_split=0.2))      \n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1D-CNN 1 Sample Per Patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Wrangling the data for CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slitting the data utilising the splitting function (xgb).\n",
    "split_df, outcome = split_xgb(outcome_df.drop('level_0', axis=1).reset_index(), WINDOW_SIZE)\n",
    "# Dropping the outcome columns.\n",
    "split_df = split_df.drop('case', axis=1)\n",
    "split_df = split_df.drop('shock', axis=1)\n",
    "split_df = split_df.drop('level_0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = split_df.copy()\n",
    "y_train = outcome\n",
    "\n",
    "# Number of patients\n",
    "N_PT = int(len(X_train)/WINDOW_SIZE)\n",
    "\n",
    "# Creating an empty dataframe of correct dimensions (patients, days, predictors)\n",
    "cnn_dat = np.empty((N_PT, WINDOW_SIZE, N_FEAT))\n",
    "pt_id = X_train['patient_id'].unique()\n",
    "pt_count = 0\n",
    "\n",
    "# Iterating through patient IDs to access their data.\n",
    "for n in pt_id:\n",
    "    pt_count \n",
    "    pt_data = X_train[X_train['patient_id']==n].copy()\n",
    "\n",
    "    # Iterating through days in the window and adding all feature values to the days.\n",
    "    for i in range(WINDOW_SIZE):\n",
    "        cnn_dat[pt_count, i, :] = np.array(pt_data[VENTR_FEATURES].iloc[i])\n",
    "    pt_count += 1\n",
    "\n",
    "X_train = cnn_dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "5/5 [==============================] - 1s 51ms/step - loss: 0.6153 - accuracy: 0.6603 - val_loss: 0.3759 - val_accuracy: 0.9000\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5293 - accuracy: 0.7885 - val_loss: 0.3053 - val_accuracy: 0.9000\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5105 - accuracy: 0.7885 - val_loss: 0.3392 - val_accuracy: 0.9000\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4862 - accuracy: 0.8013 - val_loss: 0.3653 - val_accuracy: 0.9250\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4651 - accuracy: 0.8077 - val_loss: 0.3203 - val_accuracy: 0.9250\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4415 - accuracy: 0.8077 - val_loss: 0.3426 - val_accuracy: 0.9250\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4213 - accuracy: 0.8269 - val_loss: 0.3567 - val_accuracy: 0.9250\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4043 - accuracy: 0.8462 - val_loss: 0.3477 - val_accuracy: 0.9250\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3840 - accuracy: 0.8526 - val_loss: 0.3471 - val_accuracy: 0.9250\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3664 - accuracy: 0.8526 - val_loss: 0.3527 - val_accuracy: 0.9250\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3523 - accuracy: 0.8654 - val_loss: 0.3960 - val_accuracy: 0.8750\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3422 - accuracy: 0.8590 - val_loss: 0.3452 - val_accuracy: 0.9250\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3182 - accuracy: 0.8846 - val_loss: 0.4057 - val_accuracy: 0.8500\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3032 - accuracy: 0.8974 - val_loss: 0.3841 - val_accuracy: 0.8500\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2901 - accuracy: 0.8974 - val_loss: 0.3658 - val_accuracy: 0.8750\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2734 - accuracy: 0.9038 - val_loss: 0.4472 - val_accuracy: 0.8250\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2617 - accuracy: 0.9295 - val_loss: 0.4081 - val_accuracy: 0.8500\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2554 - accuracy: 0.9167 - val_loss: 0.4375 - val_accuracy: 0.8250\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2421 - accuracy: 0.9295 - val_loss: 0.3820 - val_accuracy: 0.8500\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2432 - accuracy: 0.9167 - val_loss: 0.4373 - val_accuracy: 0.8250\n",
      "1/1 [==============================] - 0s 89ms/step\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 1s 44ms/step - loss: 0.6475 - accuracy: 0.7179 - val_loss: 0.4449 - val_accuracy: 0.9250\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5542 - accuracy: 0.7821 - val_loss: 0.3039 - val_accuracy: 0.9250\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5336 - accuracy: 0.7885 - val_loss: 0.3028 - val_accuracy: 0.9250\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5187 - accuracy: 0.7885 - val_loss: 0.3177 - val_accuracy: 0.9500\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5021 - accuracy: 0.8013 - val_loss: 0.3203 - val_accuracy: 0.9500\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4887 - accuracy: 0.8013 - val_loss: 0.2743 - val_accuracy: 0.9500\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4695 - accuracy: 0.8077 - val_loss: 0.3175 - val_accuracy: 0.9500\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4455 - accuracy: 0.8205 - val_loss: 0.2768 - val_accuracy: 0.9500\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4295 - accuracy: 0.8333 - val_loss: 0.2784 - val_accuracy: 0.9500\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4125 - accuracy: 0.8269 - val_loss: 0.2644 - val_accuracy: 0.9500\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4051 - accuracy: 0.8397 - val_loss: 0.3001 - val_accuracy: 0.9500\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3919 - accuracy: 0.8462 - val_loss: 0.2641 - val_accuracy: 0.9500\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3822 - accuracy: 0.8526 - val_loss: 0.2665 - val_accuracy: 0.9500\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3675 - accuracy: 0.8526 - val_loss: 0.3268 - val_accuracy: 0.9250\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3705 - accuracy: 0.8590 - val_loss: 0.2477 - val_accuracy: 0.9500\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3473 - accuracy: 0.8654 - val_loss: 0.3409 - val_accuracy: 0.9250\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3445 - accuracy: 0.8846 - val_loss: 0.2636 - val_accuracy: 0.9500\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3308 - accuracy: 0.8654 - val_loss: 0.2823 - val_accuracy: 0.9500\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3189 - accuracy: 0.8782 - val_loss: 0.2970 - val_accuracy: 0.9250\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3094 - accuracy: 0.9103 - val_loss: 0.2900 - val_accuracy: 0.9000\n",
      "1/1 [==============================] - 0s 76ms/step\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 1s 45ms/step - loss: 0.6243 - accuracy: 0.6731 - val_loss: 0.4273 - val_accuracy: 0.8750\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5462 - accuracy: 0.7949 - val_loss: 0.3667 - val_accuracy: 0.8750\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5247 - accuracy: 0.7949 - val_loss: 0.3756 - val_accuracy: 0.8750\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4946 - accuracy: 0.7949 - val_loss: 0.3798 - val_accuracy: 0.8750\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4737 - accuracy: 0.8013 - val_loss: 0.3893 - val_accuracy: 0.9000\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4515 - accuracy: 0.8141 - val_loss: 0.3730 - val_accuracy: 0.9000\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.4262 - accuracy: 0.8333 - val_loss: 0.3782 - val_accuracy: 0.9000\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4015 - accuracy: 0.8333 - val_loss: 0.4214 - val_accuracy: 0.9000\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3758 - accuracy: 0.8526 - val_loss: 0.3857 - val_accuracy: 0.9000\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3664 - accuracy: 0.8654 - val_loss: 0.3867 - val_accuracy: 0.9000\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3605 - accuracy: 0.8654 - val_loss: 0.4387 - val_accuracy: 0.8500\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3369 - accuracy: 0.8782 - val_loss: 0.3747 - val_accuracy: 0.9000\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3428 - accuracy: 0.8718 - val_loss: 0.4488 - val_accuracy: 0.8000\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3255 - accuracy: 0.8654 - val_loss: 0.4001 - val_accuracy: 0.8750\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3264 - accuracy: 0.9103 - val_loss: 0.4437 - val_accuracy: 0.8500\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3110 - accuracy: 0.8910 - val_loss: 0.3960 - val_accuracy: 0.8750\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2922 - accuracy: 0.8846 - val_loss: 0.4752 - val_accuracy: 0.8250\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3023 - accuracy: 0.9103 - val_loss: 0.4486 - val_accuracy: 0.8500\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2880 - accuracy: 0.8846 - val_loss: 0.4303 - val_accuracy: 0.8500\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2737 - accuracy: 0.9231 - val_loss: 0.5109 - val_accuracy: 0.8000\n",
      "1/1 [==============================] - 0s 74ms/step\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 1s 42ms/step - loss: 0.6103 - accuracy: 0.7949 - val_loss: 0.4231 - val_accuracy: 0.8750\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5315 - accuracy: 0.7949 - val_loss: 0.3875 - val_accuracy: 0.8750\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5120 - accuracy: 0.7949 - val_loss: 0.3857 - val_accuracy: 0.8750\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4826 - accuracy: 0.7949 - val_loss: 0.3710 - val_accuracy: 0.9000\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4622 - accuracy: 0.8141 - val_loss: 0.3790 - val_accuracy: 0.9000\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4365 - accuracy: 0.8141 - val_loss: 0.3654 - val_accuracy: 0.9000\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4211 - accuracy: 0.8205 - val_loss: 0.3656 - val_accuracy: 0.9000\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4102 - accuracy: 0.8397 - val_loss: 0.3887 - val_accuracy: 0.9000\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3945 - accuracy: 0.8333 - val_loss: 0.3684 - val_accuracy: 0.9000\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3980 - accuracy: 0.8397 - val_loss: 0.3389 - val_accuracy: 0.9000\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3808 - accuracy: 0.8462 - val_loss: 0.4303 - val_accuracy: 0.8750\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3680 - accuracy: 0.8654 - val_loss: 0.3449 - val_accuracy: 0.9000\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3591 - accuracy: 0.8590 - val_loss: 0.3677 - val_accuracy: 0.9000\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3524 - accuracy: 0.8590 - val_loss: 0.3895 - val_accuracy: 0.9000\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3384 - accuracy: 0.8654 - val_loss: 0.3559 - val_accuracy: 0.9000\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3266 - accuracy: 0.8654 - val_loss: 0.3773 - val_accuracy: 0.9000\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3155 - accuracy: 0.8654 - val_loss: 0.3906 - val_accuracy: 0.8750\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3070 - accuracy: 0.8846 - val_loss: 0.3562 - val_accuracy: 0.9000\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3106 - accuracy: 0.8846 - val_loss: 0.3952 - val_accuracy: 0.8500\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2836 - accuracy: 0.8974 - val_loss: 0.3667 - val_accuracy: 0.9000\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 1s 42ms/step - loss: 0.6100 - accuracy: 0.7628 - val_loss: 0.4349 - val_accuracy: 0.8750\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5524 - accuracy: 0.7949 - val_loss: 0.3650 - val_accuracy: 0.8750\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.5198 - accuracy: 0.7949 - val_loss: 0.3842 - val_accuracy: 0.8750\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4917 - accuracy: 0.8013 - val_loss: 0.3819 - val_accuracy: 0.8750\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4782 - accuracy: 0.8013 - val_loss: 0.3658 - val_accuracy: 0.9000\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4586 - accuracy: 0.8205 - val_loss: 0.3548 - val_accuracy: 0.9000\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4365 - accuracy: 0.8269 - val_loss: 0.3428 - val_accuracy: 0.9000\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4199 - accuracy: 0.8462 - val_loss: 0.3450 - val_accuracy: 0.9000\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3980 - accuracy: 0.8462 - val_loss: 0.3526 - val_accuracy: 0.9000\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3873 - accuracy: 0.8590 - val_loss: 0.3610 - val_accuracy: 0.9000\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3779 - accuracy: 0.8462 - val_loss: 0.3402 - val_accuracy: 0.9000\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3528 - accuracy: 0.8590 - val_loss: 0.3879 - val_accuracy: 0.9000\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3491 - accuracy: 0.8590 - val_loss: 0.3622 - val_accuracy: 0.9000\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3305 - accuracy: 0.8782 - val_loss: 0.3903 - val_accuracy: 0.8750\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3208 - accuracy: 0.8718 - val_loss: 0.3789 - val_accuracy: 0.8750\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3121 - accuracy: 0.8718 - val_loss: 0.3927 - val_accuracy: 0.8750\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2922 - accuracy: 0.9167 - val_loss: 0.4421 - val_accuracy: 0.8000\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2919 - accuracy: 0.9167 - val_loss: 0.4221 - val_accuracy: 0.8000\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2795 - accuracy: 0.9295 - val_loss: 0.4351 - val_accuracy: 0.8000\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2721 - accuracy: 0.9231 - val_loss: 0.4237 - val_accuracy: 0.8250\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe6380c9c10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 1s 41ms/step - loss: 0.6354 - accuracy: 0.7885 - val_loss: 0.5048 - val_accuracy: 0.8500\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5238 - accuracy: 0.8013 - val_loss: 0.4250 - val_accuracy: 0.8500\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5098 - accuracy: 0.8013 - val_loss: 0.4062 - val_accuracy: 0.8500\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4781 - accuracy: 0.8013 - val_loss: 0.4095 - val_accuracy: 0.8750\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4730 - accuracy: 0.8141 - val_loss: 0.4269 - val_accuracy: 0.8750\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4438 - accuracy: 0.8141 - val_loss: 0.3854 - val_accuracy: 0.8750\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4249 - accuracy: 0.8141 - val_loss: 0.3800 - val_accuracy: 0.8750\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4064 - accuracy: 0.8333 - val_loss: 0.4030 - val_accuracy: 0.8750\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3827 - accuracy: 0.8462 - val_loss: 0.3836 - val_accuracy: 0.8750\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3687 - accuracy: 0.8462 - val_loss: 0.3898 - val_accuracy: 0.8750\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3488 - accuracy: 0.8526 - val_loss: 0.3983 - val_accuracy: 0.8750\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3380 - accuracy: 0.8462 - val_loss: 0.4038 - val_accuracy: 0.8750\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3327 - accuracy: 0.8526 - val_loss: 0.4194 - val_accuracy: 0.8750\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3176 - accuracy: 0.8590 - val_loss: 0.4259 - val_accuracy: 0.8750\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 27ms/step - loss: 0.3022 - accuracy: 0.8590 - val_loss: 0.4302 - val_accuracy: 0.8750\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.3191 - accuracy: 0.8590 - val_loss: 0.4375 - val_accuracy: 0.8750\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2964 - accuracy: 0.9038 - val_loss: 0.4522 - val_accuracy: 0.8500\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2766 - accuracy: 0.8782 - val_loss: 0.4545 - val_accuracy: 0.8750\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2633 - accuracy: 0.8846 - val_loss: 0.4676 - val_accuracy: 0.8500\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2558 - accuracy: 0.9231 - val_loss: 0.4755 - val_accuracy: 0.8250\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fe63946d820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 1s 50ms/step - loss: 0.6284 - accuracy: 0.6795 - val_loss: 0.4017 - val_accuracy: 0.8750\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.5324 - accuracy: 0.7949 - val_loss: 0.3538 - val_accuracy: 0.8750\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5193 - accuracy: 0.7949 - val_loss: 0.3664 - val_accuracy: 0.9000\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4990 - accuracy: 0.8013 - val_loss: 0.3553 - val_accuracy: 0.9000\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4771 - accuracy: 0.8141 - val_loss: 0.3710 - val_accuracy: 0.9000\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4616 - accuracy: 0.8205 - val_loss: 0.3585 - val_accuracy: 0.9000\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4377 - accuracy: 0.8269 - val_loss: 0.3713 - val_accuracy: 0.9000\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4187 - accuracy: 0.8333 - val_loss: 0.3644 - val_accuracy: 0.9000\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.4093 - accuracy: 0.8397 - val_loss: 0.3617 - val_accuracy: 0.9000\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3838 - accuracy: 0.8462 - val_loss: 0.4204 - val_accuracy: 0.9000\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3741 - accuracy: 0.8269 - val_loss: 0.3917 - val_accuracy: 0.9000\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3608 - accuracy: 0.8526 - val_loss: 0.3895 - val_accuracy: 0.9000\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3396 - accuracy: 0.8654 - val_loss: 0.4320 - val_accuracy: 0.9000\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3322 - accuracy: 0.8590 - val_loss: 0.3928 - val_accuracy: 0.9000\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3132 - accuracy: 0.8590 - val_loss: 0.4458 - val_accuracy: 0.8500\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3092 - accuracy: 0.9038 - val_loss: 0.4058 - val_accuracy: 0.9000\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2984 - accuracy: 0.8782 - val_loss: 0.4552 - val_accuracy: 0.8500\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 23ms/step - loss: 0.3044 - accuracy: 0.8974 - val_loss: 0.4416 - val_accuracy: 0.8500\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 18ms/step - loss: 0.2974 - accuracy: 0.8654 - val_loss: 0.4257 - val_accuracy: 0.8750\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.2606 - accuracy: 0.9231 - val_loss: 0.5186 - val_accuracy: 0.7500\n",
      "1/1 [==============================] - 0s 184ms/step\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 2s 67ms/step - loss: 0.6038 - accuracy: 0.7885 - val_loss: 0.4407 - val_accuracy: 0.8750\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.5209 - accuracy: 0.8013 - val_loss: 0.3755 - val_accuracy: 0.8750\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.5183 - accuracy: 0.8013 - val_loss: 0.3613 - val_accuracy: 0.8750\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4882 - accuracy: 0.8013 - val_loss: 0.3847 - val_accuracy: 0.8750\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.4723 - accuracy: 0.8141 - val_loss: 0.3822 - val_accuracy: 0.9000\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4524 - accuracy: 0.8141 - val_loss: 0.3520 - val_accuracy: 0.9000\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.4328 - accuracy: 0.8141 - val_loss: 0.3399 - val_accuracy: 0.9000\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4172 - accuracy: 0.8462 - val_loss: 0.3616 - val_accuracy: 0.9000\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.4081 - accuracy: 0.8462 - val_loss: 0.3537 - val_accuracy: 0.9000\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3906 - accuracy: 0.8462 - val_loss: 0.3674 - val_accuracy: 0.9000\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3800 - accuracy: 0.8526 - val_loss: 0.3702 - val_accuracy: 0.9000\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3695 - accuracy: 0.8526 - val_loss: 0.3973 - val_accuracy: 0.9000\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3567 - accuracy: 0.8654 - val_loss: 0.3684 - val_accuracy: 0.9000\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3438 - accuracy: 0.8526 - val_loss: 0.3849 - val_accuracy: 0.9000\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3318 - accuracy: 0.8654 - val_loss: 0.4165 - val_accuracy: 0.8750\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 12ms/step - loss: 0.3228 - accuracy: 0.8654 - val_loss: 0.3944 - val_accuracy: 0.8750\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.3121 - accuracy: 0.8910 - val_loss: 0.4225 - val_accuracy: 0.8500\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.2954 - accuracy: 0.8974 - val_loss: 0.4002 - val_accuracy: 0.8750\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.2876 - accuracy: 0.8910 - val_loss: 0.4327 - val_accuracy: 0.8500\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.2791 - accuracy: 0.8974 - val_loss: 0.4327 - val_accuracy: 0.8500\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 1s 45ms/step - loss: 0.6135 - accuracy: 0.7962 - val_loss: 0.4448 - val_accuracy: 0.8750\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5288 - accuracy: 0.7962 - val_loss: 0.3613 - val_accuracy: 0.8750\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.5042 - accuracy: 0.7962 - val_loss: 0.3699 - val_accuracy: 0.8750\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4876 - accuracy: 0.8089 - val_loss: 0.4086 - val_accuracy: 0.9000\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4591 - accuracy: 0.8217 - val_loss: 0.3615 - val_accuracy: 0.9000\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.4555 - accuracy: 0.8153 - val_loss: 0.3513 - val_accuracy: 0.9000\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4143 - accuracy: 0.8217 - val_loss: 0.3824 - val_accuracy: 0.9000\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4021 - accuracy: 0.8599 - val_loss: 0.3991 - val_accuracy: 0.8750\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3876 - accuracy: 0.8662 - val_loss: 0.3651 - val_accuracy: 0.9000\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3827 - accuracy: 0.8662 - val_loss: 0.3669 - val_accuracy: 0.9000\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3656 - accuracy: 0.8599 - val_loss: 0.3848 - val_accuracy: 0.8750\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3536 - accuracy: 0.8662 - val_loss: 0.3755 - val_accuracy: 0.8750\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3421 - accuracy: 0.8726 - val_loss: 0.3755 - val_accuracy: 0.9000\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3303 - accuracy: 0.8790 - val_loss: 0.3859 - val_accuracy: 0.8750\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3311 - accuracy: 0.8726 - val_loss: 0.3865 - val_accuracy: 0.9000\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.3171 - accuracy: 0.8917 - val_loss: 0.3715 - val_accuracy: 0.9000\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2896 - accuracy: 0.8917 - val_loss: 0.4381 - val_accuracy: 0.8250\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2959 - accuracy: 0.9045 - val_loss: 0.4009 - val_accuracy: 0.9000\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.2745 - accuracy: 0.8981 - val_loss: 0.4152 - val_accuracy: 0.8500\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2608 - accuracy: 0.9172 - val_loss: 0.4018 - val_accuracy: 0.9000\n",
      "1/1 [==============================] - 0s 200ms/step\n",
      "Epoch 1/20\n",
      "5/5 [==============================] - 1s 51ms/step - loss: 0.6158 - accuracy: 0.7006 - val_loss: 0.4349 - val_accuracy: 0.8750\n",
      "Epoch 2/20\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.5449 - accuracy: 0.7962 - val_loss: 0.3747 - val_accuracy: 0.8750\n",
      "Epoch 3/20\n",
      "5/5 [==============================] - 0s 16ms/step - loss: 0.5201 - accuracy: 0.7962 - val_loss: 0.3824 - val_accuracy: 0.8750\n",
      "Epoch 4/20\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4944 - accuracy: 0.8153 - val_loss: 0.4056 - val_accuracy: 0.8750\n",
      "Epoch 5/20\n",
      "5/5 [==============================] - 0s 14ms/step - loss: 0.4746 - accuracy: 0.8280 - val_loss: 0.3788 - val_accuracy: 0.8750\n",
      "Epoch 6/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.4488 - accuracy: 0.8344 - val_loss: 0.3704 - val_accuracy: 0.8750\n",
      "Epoch 7/20\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.4230 - accuracy: 0.8408 - val_loss: 0.3762 - val_accuracy: 0.8750\n",
      "Epoch 8/20\n",
      "5/5 [==============================] - 0s 11ms/step - loss: 0.3943 - accuracy: 0.8599 - val_loss: 0.3731 - val_accuracy: 0.8750\n",
      "Epoch 9/20\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3811 - accuracy: 0.8662 - val_loss: 0.3769 - val_accuracy: 0.8750\n",
      "Epoch 10/20\n",
      "5/5 [==============================] - 0s 15ms/step - loss: 0.3782 - accuracy: 0.8599 - val_loss: 0.3748 - val_accuracy: 0.8750\n",
      "Epoch 11/20\n",
      "5/5 [==============================] - 0s 13ms/step - loss: 0.3300 - accuracy: 0.8790 - val_loss: 0.4176 - val_accuracy: 0.8750\n",
      "Epoch 12/20\n",
      "5/5 [==============================] - 0s 10ms/step - loss: 0.3500 - accuracy: 0.8726 - val_loss: 0.3997 - val_accuracy: 0.8750\n",
      "Epoch 13/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3102 - accuracy: 0.8790 - val_loss: 0.3998 - val_accuracy: 0.8750\n",
      "Epoch 14/20\n",
      "5/5 [==============================] - 0s 9ms/step - loss: 0.3132 - accuracy: 0.8726 - val_loss: 0.4156 - val_accuracy: 0.8750\n",
      "Epoch 15/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2879 - accuracy: 0.8790 - val_loss: 0.4304 - val_accuracy: 0.8750\n",
      "Epoch 16/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2732 - accuracy: 0.8917 - val_loss: 0.4320 - val_accuracy: 0.8750\n",
      "Epoch 17/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2585 - accuracy: 0.8981 - val_loss: 0.4567 - val_accuracy: 0.8500\n",
      "Epoch 18/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2448 - accuracy: 0.9172 - val_loss: 0.4808 - val_accuracy: 0.7750\n",
      "Epoch 19/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2329 - accuracy: 0.9172 - val_loss: 0.4903 - val_accuracy: 0.8250\n",
      "Epoch 20/20\n",
      "5/5 [==============================] - 0s 8ms/step - loss: 0.2190 - accuracy: 0.9299 - val_loss: 0.4992 - val_accuracy: 0.8250\n",
      "1/1 [==============================] - 0s 70ms/step\n"
     ]
    }
   ],
   "source": [
    "# Setting up stratified K-fold cross validation to return roc-auc scores\n",
    "strat_cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "roc_auc_scores = cross_val_score(pipeline_1, X_train, y_train, cv=strat_cv, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6180718954248366"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual Run - CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 71ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "ROC-AUC score: 0.652\n",
      "Accuracy score: 0.835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.652"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_splits = 8\n",
    "\n",
    "# Setting up lists to hold outcome variables. \n",
    "observed = []\n",
    "predicted_proba = []\n",
    "roc_auc_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "# Initialising cross-validator\n",
    "cross_validator = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Input arrays.\n",
    "X, y = cnn_dat, np.array(outcome)\n",
    "\n",
    "# Perform manual cross-validation\n",
    "for train_idx, val_idx in cross_validator.split(X, y):\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y[train_idx], y[val_idx]\n",
    "    \n",
    "    # CNN model\n",
    "    cnn_model = create_binary_classifier_model_1()\n",
    "\n",
    "    # Running the pipeline steps:\n",
    "    resh1 = DataReshaper1()\n",
    "    X_train = resh1.transform(X_train)\n",
    "    X_val = resh1.transform(X_val)\n",
    "\n",
    "    minmax = MinMaxScaler()\n",
    "    X_train = minmax.fit_transform(X_train)\n",
    "    X_val = minmax.transform(X_val)\n",
    "\n",
    "    resh2 = DataReshaper2()\n",
    "    X_train = resh2.transform(X_train)\n",
    "    X_val = resh2.transform(X_val)\n",
    "\n",
    "    # Training the model on the training data\n",
    "    cnn_model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)\n",
    "\n",
    "    # Getting the predicted probabilities (scores) for positive class (class 1)\n",
    "    y_pred_probs = cnn_model.predict(X_val)\n",
    "    y_pred_class = (y_pred_probs >= 0.5).astype(int)\n",
    "\n",
    "    # Calculating the ROC-AUC score and accuracy\n",
    "    roc_auc = roc_auc_score(y_val, y_pred_probs)\n",
    "    accu_extr = accuracy_score(np.array(y_val), y_pred_class)\n",
    "\n",
    "    # Adding values to relevant lists\n",
    "    roc_auc_scores.append(roc_auc)\n",
    "    accuracy_scores.append(accu_extr)\n",
    "    observed.append(y_val)\n",
    "    predicted_proba.append(y_pred_probs)\n",
    "\n",
    "# Calculating confidence intervals on 10-fold cross validation\n",
    "if n_splits == 10:\n",
    "    roc_low_conf = mean(roc_auc_scores) - 1.96*(np.std(roc_auc_scores))\n",
    "    roc_up_conf = mean(roc_auc_scores) + 1.96*(np.std(roc_auc_scores))\n",
    "    ac_low_conf = mean(accuracy_scores) - 1.96*(np.std(accuracy_scores))\n",
    "    ac_up_conf = mean(accuracy_scores) + 1.96*(np.std(accuracy_scores))\n",
    "    print(f\"ROC-AUC 95% CI: {roc_low_conf.round(3)} - {roc_up_conf.round(3)}\")\n",
    "    print(f\"Accuracy 95% CI: {ac_low_conf.round(3)} - {ac_up_conf.round(3)}\")\n",
    "\n",
    "print(f\"ROC-AUC score: {np.mean(roc_auc_scores).round(3)}\")\n",
    "print(f\"Accuracy score: {np.mean(accuracy_scores).round(3)}\")\n",
    "\n",
    "# Calculate average accuracy across all folds\n",
    "np.array(roc_auc_scores).mean().round(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('sktime_code')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9d480316e6260c80375bc5a8c5e8386ffb9384f976ee51805e9a6b8e3620163"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
